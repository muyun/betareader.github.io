<!doctype html>
<html lang="en">
<title>  - Raymond ZHAO WENLONG</title>
<link rel="stylesheet" href="/style.css">

<nav>
    <h1><small><a href="/index.html">Raymond ZHAO WENLONG</a></small></h1>
    <ul>
        <li><a href="/index.html"> Blog </a>
        <li><a href="/slides.html"> Slides </a>
        <li><a href="/bookshelf.html"> Bookshelf </a>
        <li><a href="/about.html"> About </a>
    </ul>
</nav>

<section class="content">
    <!--
    <header>
        
<title> Similarity Search Algorithms</title>

      </header>
      -->
    
<article class="post">
    <header>
        <h1><strong>Similarity Search Algorithms</strong></h1>
    </header>
    <p class="body"><blockquote>
<p>Similarity search refers to finding objects that have similar characteristics to the query object.</p>
</blockquote>
<h4>Similarity Search [^1]</h4>
<ul>
<li>
<p>Similarity Search in high-dimensional spaces becomes increasingly important in databases, data mining, and search engines,particularly for content-based search of feature-rich data such as audio recordings, digital photos, digital videos and other sensor data. Since feature-rich data objects are typically represented as high-dimensional feature vectors.</p>
</li>
<li>
<p>The problem of similarity search refers to finding objects that have similar characteristics to the query object.  Similarity search is usually implemented as K-Nearest Neighbor (KNN) or Approximate Nearest Neighbors (ANN) search in high-dim feature-vector space.</p>
<ul>
<li>KNN: find  the K objects that are closest to q according to a distance function</li>
<li>ANN: find K objects whose distances are within a small factor (1 + x) of the true K-nearest neighbors's distances</li>
</ul>
</li>
<li>
<p>An ideal indexing scheme for similarity search:</p>
<ul>
<li>Accurate: very close to those of the brute-force, linear-scan approach</li>
<li>Time efficient: O(logN)</li>
<li>Space efficient: the index data structure may even fit into main memory</li>
<li>High-dimensional:  the indexing scheme should work well for datasets with very high intrinsic
dimensionalities</li>
</ul>
</li>
</ul>
<h4>The related approaches</h4>
<ul>
<li>
<p>tree-based indexing methods for K-Nearest Neighbor(KNN)</p>
<ul>
<li>
<p>K-D tree: not time efficient for data with high-dim</p>
</li>
<li>
<p>TODO</p>
</li>
</ul>
</li>
<li>
<p>the indexing method: LSH  [^1]</p>
<ul>
<li>
<p>use hash functions to <strong>map similar objects into the same hash buckets with high probability</strong> .</p>
<p>using LSH functions to select candidate objects for a given query q,
and ranking the candidate objects according to their distances to q.</p>
</li>
<li>
<p>Drawback: to achieve high search accuracy, the LSH method needs to use multiple hash tables to produce a good candidate set.</p>
<ul>
<li>
<p>Experimental studies show that the basic LSH needs hundreds hash tables to achieve good search accuracy for high-dimensional datasets.</p>
</li>
<li>
<p>The size of each hash table is proportional to the number of data objects, since each table has <strong>as many
entries as the number of data objects</strong> in the dataset.
When the space requirement for the hash tables exceeds the main memory size, looking up a hash bucket may require a disk I/O, causing substantial delay to the query process.</p>
</li>
</ul>
</li>
<li>
<p>The approach does not satisfy the space-efficiency requirement.</p>
</li>
</ul>
</li>
<li>
<p>Multi-probe LSH [^1]</p>
<ul>
<li>
<p>The main idea is to build on the basic LSH indexing method, but to use <strong>a carefully derived probing
sequence to look up multiple buckets</strong> that have a high probability of containing the nearest neighbors of a query object.</p>
</li>
<li>
<p>Given the property of LSH, if an object is close to a query object q but not hashed to the same bucket as q, it is likely to be in <strong>a buckets  that is &quot;close by&quot;</strong> (i.e. the hash values of the two buckets only differ slightly).</p>
</li>
<li>
<p>By probing multiple buckets in each hash table, the method requires far fewer hash tables than previous LSH methods</p>
</li>
</ul>
</li>
</ul>
<p>[^1]:  &quot;Multi-probe LSH: Efficient indexing for high-dimensional similarity search&quot; by Q.Lv, W.Josephson, Z. Wang, M. Charikar, and K. Li, VLDB</p>
</p>
</article>




</section>


<div class="footer">
    <ul>
        <small>&copy; 2021 zhaowenlong </small>
    </ul>
</div>