<!doctype html>
<html lang="en">
<title>  - Raymond ZHAO WENLONG</title>
<link rel="stylesheet" href="/style.css">

<nav>
    <h1><small><a href="/index.html">Raymond ZHAO WENLONG</a></small></h1>
    <ul>
        <li><a href="/index.html"> Blog </a>
        <li><a href="/slides.html"> Slides </a>
        <li><a href="/bookshelf.html"> Bookshelf </a>
        <li><a href="/about.html"> About </a>
    </ul>
</nav>

<section class="content">
    <!--
    <header>
        
<title> Summary about Face Recognition with OpenCV</title>

      </header>
      -->
    
<article class="post">
    <header>
        <h1><strong>Summary about Face Recognition with OpenCV</strong></h1>
    </header>
    <p class="body"><h4>Some ideas and approachments</h4>
<h4>geometric feature</h4>
<ul>
<li>marker points ( position of eyes, ears, noses, ...) are used to build the feature vector (the distance, the angle, ...)</li>
</ul>
<h4>Eigenfaces</h4>
<ul>
<li>
<p>The idea is that a facial image is a point from a high-dim image space, and a high-dim dataset is often described by correlated variables and therefore only a few meaningful dim account for most of the information .</p>
</li>
<li>
<p>The alg</p>
<ul>
<li>
<p>[PCA] [2] alg finds the lower-dim subspace with maximum variance (with the mean) in data.
( that is, to turn a set of possibly correlated variables into a smaller set of uncorrelated variables) .</p>
</li>
<li>
<p>There is a TRICK here in computing the eigenvectors: a M x N matrix with M &gt; N can only
have N - 1 non-zero eigenvalues, so we can take the eigenvalue decomposition S of size N x N instead .</p>
</li>
<li>
<p>The approach maximizes the total scatter, but if the variance is generated by an external source like light, components with a maximum variance over all classes aren't nessarily useful for classification.</p>
</li>
</ul>
</li>
<li>
<p>The [API] [3] in OpenCV:</p>
<ul>
<li>Ptr<!-- raw HTML omitted --> createEigenFaceRecognizer(int num_components, double threshold)
(~\sources\modules\contrib\src\facerec.cpp)
<ul>
<li>
<p>Perform the PCA</p>
</li>
<li>
<p>(~\modules\core\src\matmul.cpp)
pca(data, Mat(), CV_PCA_DATA_AS_ROW, _num_components)</p>
<p>The parameter <em>num_components</em> means that how many principal components to retain (it is not
larger than the number of training samples) .</p>
</li>
<li>
<p>Get the feature vectors (y here is the principal component )
Mat y = subspaceProject(_eigenvectors, _mean, data.row(sampleIdx)</p>
<p>The parameter <em>threshold</em> here gives a upper distance limit in the prediction (It is the parameter <em>minDist</em> in the  Eigenfaces::predict())</p>
<p>Eigenfaces::predict(InputArray _src, int &amp;minClass, double &amp;minDist)</p>
<p>Each test sample is projected into PCA subspace,and get the related label based on the NORM_L2 distance in the trained subspace.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4>Fisherfaces</h4>
<h4>Local Binary Patterns Histograms (LBPH)</h4>
<ul>
<li>
<p>The idea</p>
<ul>
<li>
<p>the focus is only on extracting local features of an object, thus the features in this waywill have a low-dim implicitly.</p>
</li>
<li>
<p>Also, the local description has to be a bit robust against image illumination variations (things like scale,translation or rotation), so the Local Binary Patterns (LBP) is given to summarize the local structure in a image by comparing each pixel with its neighborhood .</p>
</li>
</ul>
</li>
<li>
<p>The [API] [3] in OpenCV
Ptr<!-- raw HTML omitted --> createLBPHFaceRecognizer(int radius,int neighbors, int grid_x, int grid_y, double threshold) Calculate lbp image</p>
<ul>
<li>elbp(src[sampleIdx],_radius,_neighbors)</li>
</ul>
<pre><code>The parameters *radius* and *neighbors* are used in the local binary pattern creation
</code></pre>
<ul>
<li>
<p>Get spatial histogram from this lbp image</p>
<p>Mat p = spatial_histogram(
lbp_image, /* lbp_image <em>/
static_cast<!-- raw HTML omitted -->(std::pow(2.0, static_cast<!-- raw HTML omitted -->(_neighbors))), /</em> number of possible patterns <em>/
_grid_x, /</em> grid size x <em>/
_grid_y, /</em> grid size y */
true)</p>
<p>The parameters <em>gird_x</em> and <em>grid_y</em> control the grid size of the spatial histograms.
At last the feature vectors (p here is the spatial histogram) are given .</p>
<p>LBPH::predict(InputArray _src, int &amp;minClass, double &amp;minDist)</p>
<p>compareHist(_histograms[sampleIdx], query, CV_COMP_CHISQR)</p>
<p>Chi-square test is used for the distance measure</p>
</li>
</ul>
</li>
</ul>
<h4>The Performance</h4>
<ul>
<li>
<p>Receiver operating characteristic ( [ROC]  )</p>
<ul>
<li>A ROC space is defined by TAR (I.e., the rate of genuine attempts accepted) and FAR(I.e., the rate of
impostor attempts accepted) as y and x axes respectively, which depicts relative trade-offs between
true positive (benefits) and false positive (costs).</li>
</ul>
</li>
<li>
<p>Cumulative Match Characteristic (CMC)</p>
<ul>
<li>It plots the probability of identification against the returned 1:N candidate list size.
It shows the probability that a given user appears in different sized candidate lists.</li>
</ul>
</li>
</ul>
<h4>Reference</h4>
<ul>
<li><a href="http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html">Face Recognition with OpenCV</a></li>
<li><a href="http://en.wikipedia.org/wiki/Eigenface/">Eigenface</a></li>
<li><a href="http://docs.opencv.org/trunk/modules/contrib/doc/facerec/facerec_api.html">FaceRecognizer API</a></li>
<li><a href="http://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC</a></li>
</ul>
</p>
</article>




</section>


<div class="footer">
    <ul>
        <small>&copy; 2021 zhaowenlong </small>
    </ul>
</div>